import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv
from pathlib import Path

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ì—ì„œ .env íŒŒì¼ ì°¾ê¸°
env_path = Path(__file__).resolve().parent / '.env'
print(f"Looking for .env file at: {env_path}")

if not env_path.exists():
    print(f"Warning: .env file not found at {env_path}")
else:
    print(f".env file found and exists")
    
# .env íŒŒì¼ ë¡œë“œ
load_dotenv(dotenv_path=env_path)

# í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸° ì „ì— í˜„ì¬ í™˜ê²½ë³€ìˆ˜ ìƒíƒœ ì¶œë ¥
print("\nCurrent environment variables:")
for key in ['DISCORD_WEBHOOK_URL', 'STOCK_NAME', 'DATA_DAYS']:
    print(f"{key} raw value: '{os.getenv(key)}'")

# í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
DISCORD_WEBHOOK_URL = os.getenv('DISCORD_WEBHOOK_URL')
STOCK_NAMES = [name.strip() for name in os.getenv('STOCK_NAME', 'í‹°ì›¨ì´í™€ë”©ìŠ¤').split(',')]
DATA_DAYS = int(os.getenv('DATA_DAYS', '200').strip())  # ê¸°ë³¸ê°’ ì„¤ì •

def get_krx_code(market=None, force_update=False):
    """
    ì£¼ì‹ ì¢…ëª© ì½”ë“œ ì¡°íšŒ (ETF í¬í•¨)
    force_update: Trueì¼ ê²½ìš° ìºì‹œëœ íŒŒì¼ì„ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
    """
    # ìºì‹œ íŒŒì¼ ê²½ë¡œ
    cache_dir = 'stock_data'
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)
    cache_file = os.path.join(cache_dir, 'krx_code.csv')
    
    # ì˜¤ëŠ˜ ë‚ ì§œ
    today = datetime.now().date()
    
    # ìºì‹œëœ íŒŒì¼ì´ ìˆê³  ì˜¤ëŠ˜ ìƒì„±ëœ ê²ƒì´ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
    if not force_update and os.path.exists(cache_file):
        file_mtime = datetime.fromtimestamp(os.path.getmtime(cache_file)).date()
        if file_mtime == today:
            print(f"ìºì‹œëœ ì¢…ëª© ì½”ë“œ ë°ì´í„° ì‚¬ìš© (ìƒì„±ì¼: {file_mtime})")
            return pd.read_csv(cache_file)
    
    print("KRXì—ì„œ ì¢…ëª© ì½”ë“œ ë°ì´í„° ìƒˆë¡œ ê°€ì ¸ì˜¤ê¸°...")
    
    # ì¼ë°˜ ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    stock_code = None
    try:
        url = 'http://data.krx.co.kr/comm/bldAttendant/getJsonData.cmd'
        stock_params = {
            'bld': 'dbms/MDC/STAT/standard/MDCSTAT01901',
            'mktId': 'ALL',
            'share': '1',
            'csvxls_isNo': 'false',
        }
        headers = {
            'Referer': 'http://data.krx.co.kr/contents/MDC/MDI/mdiLoader',
            'User-Agent': 'Mozilla/5.0',
            'X-Requested-With': 'XMLHttpRequest'
        }
        response = requests.post(url, data=stock_params, headers=headers)
        stock_data = response.json()
        if 'OutBlock_1' in stock_data:
            stock_code = pd.DataFrame(stock_data['OutBlock_1'])
            stock_code = stock_code.rename(columns={'ISU_SRT_CD': 'code', 'ISU_ABBRV': 'name'})
            print(f"ì¼ë°˜ ì£¼ì‹ ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {len(stock_code)}ê°œ")
    except Exception as e:
        print(f"ì¼ë°˜ ì£¼ì‹ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
    
    # ETF ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    etf_code = None
    try:
        etf_params = {
            'bld': 'dbms/MDC/STAT/standard/MDCSTAT04301',
            'mktId': 'ETF',
            'share': '1',
            'csvxls_isNo': 'false',
        }
        response = requests.post(url, data=etf_params, headers=headers)
        etf_data = response.json()
        if 'OutBlock_1' in etf_data:
            etf_code = pd.DataFrame(etf_data['OutBlock_1'])
            etf_code = etf_code.rename(columns={'ISU_SRT_CD': 'code', 'ISU_ABBRV': 'name'})
            print(f"ETF ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {len(etf_code)}ê°œ")
    except Exception as e:
        print(f"ETF ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
    
    # ë°ì´í„° í•©ì¹˜ê¸°
    if stock_code is not None and etf_code is not None:
        code_df = pd.concat([stock_code[['name', 'code']], etf_code[['name', 'code']]], ignore_index=True)
    elif stock_code is not None:
        code_df = stock_code[['name', 'code']]
    elif etf_code is not None:
        code_df = etf_code[['name', 'code']]
    else:
        raise Exception("ì£¼ì‹ ë° ETF ë°ì´í„°ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ì¢…ëª©ì½”ë“œ í˜•ì‹ í†µì¼
    code_df['code'] = code_df['code'].astype(str).str.zfill(6)
    
    # ì¤‘ë³µ ì œê±°
    code_df = code_df.drop_duplicates(subset=['code'], keep='first')
    
    # ìºì‹œ íŒŒì¼ë¡œ ì €ì¥
    code_df.to_csv(cache_file, index=False)
    print(f"ì „ì²´ {len(code_df)}ê°œ ì¢…ëª© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {cache_file}")
    
    return code_df

def is_trading_day(date):
    """
    ì£¼ì–´ì§„ ë‚ ì§œê°€ ê±°ë˜ì¼ì¸ì§€ í™•ì¸
    - ì£¼ë§(í† ,ì¼) ì œì™¸
    - ê³µíœ´ì¼ì€ ë³„ë„ ì²´í¬ í•„ìš”
    """
    # ì£¼ë§ ì²´í¬
    if date.weekday() >= 5:  # 5=í† ìš”ì¼, 6=ì¼ìš”ì¼
        return False
    return True

def calculate_macd_daily(df):
    """
    ì¼ê°„ MACD ì§€í‘œ ê³„ì‚° (12, 26, 9)
    
    1. MACD Line = 12ì¼ EMA - 26ì¼ EMA
    2. Signal Line = MACD Lineì˜ 9ì¼ EMA
    3. MACD Histogram = MACD Line - Signal Line
    """
    # ì¢…ê°€ ë°ì´í„°
    close = df['close']
    
    # EMA ê³„ì‚°ì„ ìœ„í•œ ì•ŒíŒŒê°’ ê³„ì‚° - ê¸°ë³¸ê°’ ì‚¬ìš©
    alpha12 = 2 / (12 + 1)
    alpha26 = 2 / (26 + 1)
    alpha9 = 2 / (9 + 1)
    
    # 1. EMA ê³„ì‚°
    # 1-1. 12ì¼ EMA (ë‹¨ê¸°) ê³„ì‚° - ì´ˆê¸°ê°’ì„ SMAë¡œ ì„¤ì •
    sma12 = close.rolling(window=12, min_periods=1).mean()
    ema12 = pd.Series(index=close.index, dtype='float64')
    ema12.iloc[0] = sma12.iloc[0]
    
    for i in range(1, len(close)):
        ema12.iloc[i] = close.iloc[i] * alpha12 + ema12.iloc[i-1] * (1 - alpha12)
    
    df['ema12'] = ema12.round(4)
    
    # 1-2. 26ì¼ EMA (ì¥ê¸°) ê³„ì‚° - ì´ˆê¸°ê°’ì„ SMAë¡œ ì„¤ì •
    sma26 = close.rolling(window=26, min_periods=1).mean()
    ema26 = pd.Series(index=close.index, dtype='float64')
    ema26.iloc[0] = sma26.iloc[0]
    
    for i in range(1, len(close)):
        ema26.iloc[i] = close.iloc[i] * alpha26 + ema26.iloc[i-1] * (1 - alpha26)
    
    df['ema26'] = ema26.round(4)
    
    # 2. MACD Line ê³„ì‚°
    macd_line = (ema12 - ema26)
    df['macd_line'] = macd_line.round(4)
    
    # 3. Signal Line ê³„ì‚° - ì´ˆê¸°ê°’ì„ SMAë¡œ ì„¤ì •
    sma9 = macd_line.rolling(window=9, min_periods=1).mean()
    signal_line = pd.Series(index=macd_line.index, dtype='float64')
    signal_line.iloc[0] = sma9.iloc[0]
    
    for i in range(1, len(macd_line)):
        signal_line.iloc[i] = macd_line.iloc[i] * alpha9 + signal_line.iloc[i-1] * (1 - alpha9)
    
    df['signal_line'] = signal_line.round(4)
    
    # 4. MACD Histogram ê³„ì‚° (í¸í–¥ ë³´ì • ì—†ìŒ)
    df['macd_hist'] = (df['macd_line'] - df['signal_line']).round(2)
    
    return df

def calculate_macd_weekly(df):
    """
    ì£¼ê°„ MACD ì§€í‘œ ê³„ì‚° (12, 26, 9)
    
    1. MACD Line = 12ì¼ EMA - 26ì¼ EMA
    2. Signal Line = MACD Lineì˜ 9ì¼ EMA
    3. MACD Histogram = MACD Line - Signal Line
    """
    # ì¢…ê°€ ë°ì´í„°
    close = df['close']
    
    # EMA ê³„ì‚°ì„ ìœ„í•œ ì•ŒíŒŒê°’ ê³„ì‚° - ì£¼ê°„ ë°ì´í„°ìš© ì¡°ì •ê°’ ì‚¬ìš©
    alpha12 = 2 / (12 + 1.15)
    alpha26 = 2 / (26 + 1.15)
    alpha9 = 2 / (9 + 1.15)
    
    # 1. EMA ê³„ì‚°
    # 1-1. 12ì¼ EMA (ë‹¨ê¸°) ê³„ì‚° - ì´ˆê¸°ê°’ì„ SMAë¡œ ì„¤ì •
    sma12 = close.rolling(window=12, min_periods=1).mean()
    ema12 = pd.Series(index=close.index, dtype='float64')
    ema12.iloc[0] = sma12.iloc[0]
    
    for i in range(1, len(close)):
        ema12.iloc[i] = close.iloc[i] * alpha12 + ema12.iloc[i-1] * (1 - alpha12)
    
    df['ema12'] = ema12.round(4)
    
    # 1-2. 26ì¼ EMA (ì¥ê¸°) ê³„ì‚° - ì´ˆê¸°ê°’ì„ SMAë¡œ ì„¤ì •
    sma26 = close.rolling(window=26, min_periods=1).mean()
    ema26 = pd.Series(index=close.index, dtype='float64')
    ema26.iloc[0] = sma26.iloc[0]
    
    for i in range(1, len(close)):
        ema26.iloc[i] = close.iloc[i] * alpha26 + ema26.iloc[i-1] * (1 - alpha26)
    
    df['ema26'] = ema26.round(4)
    
    # 2. MACD Line ê³„ì‚°
    macd_line = (ema12 - ema26)
    df['macd_line'] = macd_line.round(4)
    
    # 3. Signal Line ê³„ì‚° - ì´ˆê¸°ê°’ì„ SMAë¡œ ì„¤ì •
    sma9 = macd_line.rolling(window=9, min_periods=1).mean()
    signal_line = pd.Series(index=macd_line.index, dtype='float64')
    signal_line.iloc[0] = sma9.iloc[0]
    
    for i in range(1, len(macd_line)):
        signal_line.iloc[i] = macd_line.iloc[i] * alpha9 + signal_line.iloc[i-1] * (1 - alpha9)
    
    df['signal_line'] = signal_line.round(4)
    
    # 4. MACD Histogram ê³„ì‚° - í¸í–¥ ë³´ì • ì ìš©
    macd_hist = (df['macd_line'] - df['signal_line'])
    bias_correction = -1.0
    df['macd_hist'] = (macd_hist + bias_correction).round(2)
    
    return df

def get_stock_price(code, num_of_pages, sort_date = True):
    # ë°ì´í„°ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
    data_dir = 'stock_data'
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    
    # CSV íŒŒì¼ ê²½ë¡œ
    file_path = os.path.join(data_dir, f'{code}_daily.csv')
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    existing_df = pd.DataFrame()
    if os.path.exists(file_path):
        existing_df = pd.read_csv(file_path)
        existing_df['date'] = pd.to_datetime(existing_df['date'])
        
    # ìµœì‹  ë°ì´í„° ë‚ ì§œ í™•ì¸
    latest_date = existing_df['date'].max() if not existing_df.empty else pd.Timestamp.min
    
    # ì˜¤ëŠ˜ ë‚ ì§œ
    today = pd.Timestamp.now().normalize()
    
    # ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„
    df = pd.DataFrame()
    
    # ë°ì´í„° ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš°: íŒŒì¼ì´ ì—†ê±°ë‚˜, ìµœì‹  ë°ì´í„°ê°€ ì˜¤ë˜ëœ ê²½ìš°
    if not os.path.exists(file_path) or (latest_date < today and is_trading_day(today)):
        print(f"ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘: {code}")
        
        url = f"http://finance.naver.com/item/sise_day.nhn?code={code}"
        headers = {'User-agent': 'Mozilla/5.0'} 
        response = requests.get(url=url, headers=headers)
        response.encoding = 'euc-kr'  # ë„¤ì´ë²„ ê¸ˆìœµì€ EUC-KR ì¸ì½”ë”© ì‚¬ìš©
        bs = BeautifulSoup(response.text, 'html.parser')
        pgrr = bs.find("td", class_="pgRR")
        last_page = int(pgrr.a["href"].split('=')[-1])
        
        pages = min(last_page, num_of_pages)
        new_df = pd.DataFrame()

        for page in range(1, pages+1):
            page_url = '{}&page={}'.format(url, page)
            response = requests.get(page_url, headers={'User-agent': 'Mozilla/5.0'})
            response.encoding = 'euc-kr'
            new_df = pd.concat([new_df, pd.read_html(response.text, encoding='euc-kr')[0]], ignore_index=True)
        
        new_df = new_df.rename(columns={'ë‚ ì§œ':'date','ì¢…ê°€':'close','ì „ì¼ë¹„':'diff'
                    ,'ì‹œê°€':'open','ê³ ê°€':'high','ì €ê°€':'low','ê±°ë˜ëŸ‰':'volume'})
        new_df['date'] = pd.to_datetime(new_df['date'])
        new_df = new_df.dropna()
        
        # ìˆ«ì ë°ì´í„° ì²˜ë¦¬
        numeric_columns = ['close', 'open', 'high', 'low', 'volume']
        for col in numeric_columns:
            if new_df[col].dtype == object:
                new_df[col] = new_df[col].str.replace(',', '').astype(int)
            else:
                new_df[col] = new_df[col].astype(int)
        
        if new_df['diff'].dtype == object:
            new_df['diff'] = new_df['diff'].str.extract('([\d,]+)').fillna('0')
            new_df['diff'] = new_df['diff'].str.replace(',', '').astype(int)
        else:
            new_df['diff'] = new_df['diff'].astype(int)
        
        new_df = new_df[['date', 'open', 'high', 'low', 'close', 'diff', 'volume']]
        
        # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„° ë³‘í•©
        if existing_df.empty:
            df = new_df
        else:
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ë°ì´í„° ë³‘í•©
            df = pd.concat([existing_df, new_df])
            df = df.drop_duplicates(subset=['date'], keep='last')
        
        # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        if sort_date:
            df = df.sort_values(by='date').reset_index(drop=True)
            
        # MACD ê³„ì‚°
        df = calculate_macd_daily(df)
        
        # ë°ì´í„° ì €ì¥
        save_columns = ['date', 'open', 'high', 'low', 'close', 'diff', 'volume', 
                       'ema12', 'ema26', 'macd_line', 'signal_line', 'macd_hist']
        df[save_columns].to_csv(file_path, index=False)
    else:
        df = existing_df
    
    # ìµœê·¼ 30ì£¼ ë°ì´í„° í•„í„°ë§
    thirty_weeks_ago = datetime.now() - timedelta(weeks=30)
    df = df[df['date'] >= thirty_weeks_ago]
    
    return df

def get_weekly_data(df, code):
    """
    ì¼ê°„ ë°ì´í„°ë¥¼ ì£¼ê°„ ë°ì´í„°ë¡œ ë³€í™˜ (ê¸ˆìš”ì¼ ê¸°ì¤€)
    """
    # ë°ì´í„°ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
    data_dir = 'stock_data'
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    
    # ì£¼ê°„ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    file_path = os.path.join(data_dir, f'{code}_weekly.csv')
    
    # ê¸°ì¡´ ì£¼ê°„ ë°ì´í„° ë¡œë“œ
    existing_weekly_df = pd.DataFrame()
    if os.path.exists(file_path):
        existing_weekly_df = pd.read_csv(file_path)
        existing_weekly_df['date'] = pd.to_datetime(existing_weekly_df['date'])
    
    print(f"ì…ë ¥ ë°ì´í„° ìˆ˜: {len(df)}")
    
    # ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    df = df.sort_values('date', ascending=True)
    
    # ì£¼ì°¨ ê³„ì‚° ë°©ì‹ ë³€ê²½ (%Y-%U -> %Y-%W: ì›”ìš”ì¼ ì‹œì‘ ê¸°ì¤€)
    df['year_week'] = df['date'].dt.strftime('%Y-%W')
    
    # ì£¼ê°„ ë°ì´í„° ê³„ì‚°
    weekly_data = []
    for year_week, group in df.groupby('year_week'):
        if len(group) > 0:
            data = {
                'date': group['date'].iloc[-1],    # ì£¼ì˜ ë§ˆì§€ë§‰ ê±°ë˜ì¼
                'open': group['open'].iloc[0],     # ì£¼ì˜ ì²« ê±°ë˜ì¼ ì‹œê°€
                'high': group['high'].max(),       # ì£¼ì˜ ê³ ê°€
                'low': group['low'].min(),         # ì£¼ì˜ ì €ê°€
                'close': group['close'].iloc[-1],  # ì£¼ì˜ ë§ˆì§€ë§‰ ê±°ë˜ì¼ ì¢…ê°€
                'volume': group['volume'].sum()    # ì£¼ê°„ ê±°ë˜ëŸ‰ í•©ê³„
            }
            weekly_data.append(data)
    
    new_weekly_df = pd.DataFrame(weekly_data)
    
    # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„° ë³‘í•©
    if existing_weekly_df.empty:
        weekly_df = new_weekly_df
    else:
        # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ë°ì´í„° ë³‘í•©
        weekly_df = pd.concat([existing_weekly_df, new_weekly_df])
        weekly_df = weekly_df.drop_duplicates(subset=['date'], keep='last')
    
    # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    weekly_df = weekly_df.sort_values(by='date').reset_index(drop=True)
    
    # ë°ì´í„° í™•ì¸ìš© ì¶œë ¥
    print(f"ì£¼ê°„ ë°ì´í„° ìˆ˜: {len(weekly_df)}")
    
    # ì „ì£¼ ëŒ€ë¹„ ì°¨ì´ ê³„ì‚°
    weekly_df['diff'] = weekly_df['close'].diff().fillna(0).astype(int)
    
    # ì£¼ê°„ ë°ì´í„°ë¡œ MACD ê³„ì‚°
    weekly_df = calculate_macd_weekly(weekly_df)
    
    # ë°ì´í„° ì €ì¥
    save_columns = ['date', 'open', 'high', 'low', 'close', 'diff', 'volume', 
                   'ema12', 'ema26', 'macd_line', 'signal_line', 'macd_hist']
    weekly_df[save_columns].to_csv(file_path, index=False)
        
    return weekly_df.tail(4)

def check_macd_signals(weekly_df):
    """
    ì£¼ê°„ MACD íˆìŠ¤í† ê·¸ë¨ì˜ ë¶€í˜¸ ë³€í™”ë¥¼ í™•ì¸í•˜ì—¬ ë§¤ìˆ˜/ë§¤ë„ ì‹œê·¸ë„ ìƒì„±
    """
    signals = []
    
    # ìµœì†Œ 2ì£¼ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”
    if len(weekly_df) < 2:
        return signals
    
    # ìµœê·¼ 2ì£¼ê°„ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©
    last_two_weeks = weekly_df.tail(2)
    prev_hist = last_two_weeks.iloc[0]['macd_hist']
    curr_hist = last_two_weeks.iloc[1]['macd_hist']
    curr_date = last_two_weeks.iloc[1]['date']
    curr_price = last_two_weeks.iloc[1]['close']
    
    # ìŒë´‰ -> ì–‘ë´‰ (ë§¤ìˆ˜ ì‹œê·¸ë„)
    if prev_hist < 0 and curr_hist > 0:
        signals.append({
            'type': 'BUY',
            'date': curr_date,
            'price': curr_price,
            'reason': f'MACD íˆìŠ¤í† ê·¸ë¨ ë¶€í˜¸ ì „í™˜ (ìŒ â†’ ì–‘): {prev_hist:.2f} â†’ {curr_hist:.2f}'
        })
    
    # ì–‘ë´‰ -> ìŒë´‰ (ë§¤ë„ ì‹œê·¸ë„)
    elif prev_hist > 0 and curr_hist < 0:
        signals.append({
            'type': 'SELL',
            'date': curr_date,
            'price': curr_price,
            'reason': f'MACD íˆìŠ¤í† ê·¸ë¨ ë¶€í˜¸ ì „í™˜ (ì–‘ â†’ ìŒ): {prev_hist:.2f} â†’ {curr_hist:.2f}'
        })
    
    return signals

# Discord ì•Œë¦¼ ê¸°ëŠ¥ ì¶”ê°€
def send_to_discord(message, webhook_url):
    """Discordë¡œ ë©”ì‹œì§€ ì „ì†¡"""
    data = {
        "content": message,
        "username": "ì£¼ì‹ ì•Œë¦¬ë¯¸",
        "avatar_url": "https://cdn-icons-png.flaticon.com/512/2474/2474475.png"
    }
    
    try:
        response = requests.post(webhook_url, json=data)
        response.raise_for_status()
        return True
    except Exception as e:
        print(f"Discord ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
        return False

def format_discord_message(item_name, stock, signals, weekly_df):
    """Discord ë©”ì‹œì§€ í¬ë§·íŒ…"""
    message = f"ğŸ”” **{item_name}({stock}) ì£¼ê°„ MACD ë¶„ì„ ê²°ê³¼**\n\n"
    
    # ìµœê·¼ 4ì£¼ ë°ì´í„° ìš”ì•½
    message += "ğŸ“Š **ìµœê·¼ 4ì£¼ ìš”ì•½**\n```\n"
    message += "ë‚ ì§œ          ì¢…ê°€      ì „ì£¼ë¹„    MACD\n"
    message += "-" * 40 + "\n"
    
    for _, row in weekly_df.iterrows():
        message += f"{row['date'].strftime('%Y-%m-%d')}  "
        message += f"{row['close']:8,}  "
        message += f"{row['diff']:+8,}  "
        message += f"{row['macd_hist']:+6.2f}\n"
    message += "```\n"
    
    # ë§¤ë§¤ ì‹œê·¸ë„
    if signals:
        for signal in signals:
            if signal['type'] == 'BUY':
                message += "\nğŸ”µ **ë§¤ìˆ˜ ì‹œê·¸ë„ ë°œìƒ!**\n"
            else:
                message += "\nğŸ”´ **ë§¤ë„ ì‹œê·¸ë„ ë°œìƒ!**\n"
            
            message += f"ğŸ“… ë‚ ì§œ: {signal['date'].strftime('%Y-%m-%d')}\n"
            message += f"ğŸ’° ê°€ê²©: {signal['price']:,}ì›\n"
            message += f"ğŸ“Š {signal['reason']}\n"
    else:
        message += "\nğŸ’¡ í˜„ì¬ ë§¤ë§¤ ì‹œê·¸ë„ ì—†ìŒ\n"
    
    return message

def analyze_stocks():
    """ì—¬ëŸ¬ ì£¼ì‹ ë¶„ì„ ë° Discord ì•Œë¦¼ ì „ì†¡"""
    all_results = []
    error_stocks = []
    
    for item_name in STOCK_NAMES:
        try:
            print(f"\n=== {item_name} ë¶„ì„ ì‹œì‘ ===")
            stock = get_krx_code().query("name==@item_name")['code'].iloc[0]
            df = get_stock_price(stock, DATA_DAYS)
            weekly_df = get_weekly_data(df, stock)
            
            if weekly_df is not None:
                signals = check_macd_signals(weekly_df)
                
                # ì½˜ì†” ì¶œë ¥
                print(f"\n=== {item_name}({stock}) ì£¼ê°„ MACD ë¶„ì„ ê²°ê³¼ ===")
                print("\nì£¼ê°„          ì¢…ê°€      ì „ì£¼ë¹„    ê±°ë˜ëŸ‰     MACDíˆìŠ¤í† ê·¸ë¨")
                print("-" * 65)

                for _, row in weekly_df.iterrows():
                    print(f"{row['date'].strftime('%Y-%m-%d')}  "
                          f"{row['close']:8,}  "
                          f"{row['diff']:+8,}  "
                          f"{row['volume']:10,}  "
                          f"{row['macd_hist']:+8.2f}")
                
                # Discord ì•Œë¦¼ ì „ì†¡
                if DISCORD_WEBHOOK_URL:
                    message = format_discord_message(item_name, stock, signals, weekly_df)
                    send_to_discord(message, DISCORD_WEBHOOK_URL)
                
                all_results.append({
                    'name': item_name,
                    'code': stock,
                    'signals': signals is not None and len(signals) > 0
                })
                
        except Exception as e:
            error_message = f"{item_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            print(error_message)
            error_stocks.append(item_name)
            if DISCORD_WEBHOOK_URL:
                send_to_discord(f"âš ï¸ **ì˜¤ë¥˜ ë°œìƒ**\n{error_message}", DISCORD_WEBHOOK_URL)
    
    # ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½
    if DISCORD_WEBHOOK_URL and all_results:
        summary = "ğŸ“Š **ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½**\n\n"
        summary += f"âœ… ë¶„ì„ ì™„ë£Œ: {len(all_results)}ê°œ ì¢…ëª©\n"
        if error_stocks:
            summary += f"âŒ ë¶„ì„ ì‹¤íŒ¨: {len(error_stocks)}ê°œ ì¢…ëª© ({', '.join(error_stocks)})\n"
        
        signals_found = [result['name'] for result in all_results if result['signals']]
        if signals_found:
            summary += f"\nğŸ”” ë§¤ë§¤ ì‹œê·¸ë„ ë°œìƒ ì¢…ëª©: {', '.join(signals_found)}"
        else:
            summary += "\nğŸ’¡ ë§¤ë§¤ ì‹œê·¸ë„ì´ ë°œìƒí•œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤."
        
        send_to_discord(summary, DISCORD_WEBHOOK_URL)
    
    return {
        'success': True,
        'analyzed': len(all_results),
        'errors': len(error_stocks)
    }

# CLI ì‹¤í–‰ìš© ë©”ì¸ í•¨ìˆ˜
def main():
    if DISCORD_WEBHOOK_URL:
        print("Discord ì•Œë¦¼ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("Warning: DISCORD_WEBHOOK_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ Discord ì•Œë¦¼ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    
    print(f"ë¶„ì„í•  ì¢…ëª©: {', '.join(STOCK_NAMES)}")
    
    # ë¶„ì„ ì‹¤í–‰
    analyze_stocks()

if __name__ == "__main__":
    main()